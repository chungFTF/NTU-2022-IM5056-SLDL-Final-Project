{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lu2-Z16ZcjP",
        "outputId": "e9833949-1de4-49ae-ba3a-0f2be8860b8e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\oplab\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from natsort import natsorted\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "import emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\oplab\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\oplab\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\oplab\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 全部文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "filename = os.listdir('../data/tweet_train/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['adamlevine.csv',\n",
              " 'aliciakeys.csv',\n",
              " 'andy_murray.csv',\n",
              " 'anselElgort.csv',\n",
              " 'avrilLavigne.csv',\n",
              " 'barackObama.csv',\n",
              " 'benzema.csv',\n",
              " 'bethanyMota.csv',\n",
              " 'beyonce.csv',\n",
              " 'billGates.csv',\n",
              " 'bradPaisley.csv',\n",
              " 'brunoMars.csv',\n",
              " 'cP3.csv',\n",
              " 'caitlyn_Jenner.csv',\n",
              " 'calvinHarris.csv',\n",
              " 'caradelevingne.csv',\n",
              " 'chrisEvans.csv',\n",
              " 'chrisrock.csv',\n",
              " 'ciara.csv',\n",
              " 'codySimpson.csv',\n",
              " 'conanOBrien.csv',\n",
              " 'dAVID_LYNCH.csv',\n",
              " 'drake.csv',\n",
              " 'dwightHoward.csv',\n",
              " 'dwyaneWade.csv',\n",
              " 'dylanobrien.csv',\n",
              " 'edsheeran.csv',\n",
              " 'elonmusk.csv',\n",
              " 'eminem.csv',\n",
              " 'floydMayweather.csv',\n",
              " 'gordonRamsay.csv',\n",
              " 'jHarden13.csv',\n",
              " 'jason_mraz.csv',\n",
              " 'jessicaSimpson.csv',\n",
              " 'jessicaalba.csv',\n",
              " 'jessieJ.csv',\n",
              " 'jimmyfallon.csv',\n",
              " 'jimmykimmel.csv',\n",
              " 'johnCena.csv',\n",
              " 'johnlegend.csv',\n",
              " 'jtimberlake.csv',\n",
              " 'justinbieber.csv',\n",
              " 'kanyewest.csv',\n",
              " 'katyperry.csv',\n",
              " 'kendricklamar.csv',\n",
              " 'kerrywashington.csv',\n",
              " 'kevinSpacey.csv',\n",
              " 'kobebryant.csv',\n",
              " 'kyrieIrving.csv',\n",
              " 'ladygaga.csv',\n",
              " 'leoDiCaprio.csv',\n",
              " 'ludacris.csv',\n",
              " 'luisSuarez9.csv',\n",
              " 'magicJohnson.csv',\n",
              " 'mariahCarey.csv',\n",
              " 'marthaStewart.csv',\n",
              " 'michelleObama.csv',\n",
              " 'nICKIMINAJ.csv',\n",
              " 'neymarjr.csv',\n",
              " 'paulpierce34.csv',\n",
              " 'pharrell.csv',\n",
              " 'pitbull.csv',\n",
              " 'rafaelNadal.csv',\n",
              " 'rainnwilson.csv',\n",
              " 'randyOrton.csv',\n",
              " 'ricky_martin.csv',\n",
              " 'rihanna.csv',\n",
              " 'robbiewilliams.csv',\n",
              " 'robertDowneyJr.csv',\n",
              " 'robertsEmma.csv',\n",
              " 'rogerfederer.csv',\n",
              " 'samuelLJackson.csv',\n",
              " 'scottDisick.csv',\n",
              " 'serenawilliams.csv',\n",
              " 'shakira.csv',\n",
              " 'shawnMendes.csv',\n",
              " 'shaymitch.csv',\n",
              " 'simonCowell.csv',\n",
              " 'slash.csv',\n",
              " 'snoopDogg.csv',\n",
              " 'stephenCurry30.csv',\n",
              " 'steveCarell.csv',\n",
              " 'steveNash.csv',\n",
              " 'taylorswift13.csv',\n",
              " 'theRock.csv',\n",
              " 'tigerWoods.csv',\n",
              " 'tomFelton.csv',\n",
              " 'tomhanks.csv',\n",
              " 'tonyRobbins.csv',\n",
              " 'tonyhawk.csv',\n",
              " 'twhiddleston.csv',\n",
              " 'usainbolt.csv',\n",
              " 'vanessaHudgens.csv',\n",
              " 'victoriabeckham.csv',\n",
              " 'wayneRooney.csv',\n",
              " 'wizkhalifa.csv',\n",
              " 'zacEfron.csv',\n",
              " 'zaynmalik.csv',\n",
              " 'zedd.csv',\n",
              " 'zendaya.csv',\n",
              " 'zooeyDeschanel.csv']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file = natsorted(filename)\n",
        "file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a51orwV-yuzS"
      },
      "outputs": [],
      "source": [
        "def combineRow(path):\n",
        "  tweet_data = []\n",
        "  for f in file:  \n",
        "    data = pd.read_csv(path+f)\n",
        "    tmp = data.copy()\n",
        "    m = tmp['tweet'].str.contains('\\w+')\n",
        "    tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
        "    tweet_data.append(tmp_)\n",
        "  tweet_data = pd.concat(tweet_data)\n",
        "  tweet_data = tweet_data.reset_index(drop=True)\n",
        "  return tweet_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "yLpshNemzaEs",
        "outputId": "5fa105ea-b965-4b73-9c67-62db8f30eb68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n",
            "/var/folders/xz/_bzb1gcs00d7drk52xwkbckm0000gn/T/ipykernel_3825/611672685.py:7: FutureWarning: ['twitter_id'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  tmp_ = tmp[m].groupby((~m).cumsum(), as_index=False).agg(', '.join)\n"
          ]
        }
      ],
      "source": [
        "tweet_data = combineRow('../data/tweet_train/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 處理emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-08-20 17:22:27+00:00, 2021-08-06 18:02:13...</td>\n",
              "      <td>b'Puppies and music \\xe2\\x80\\x94 just the thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-07-10 20:14:18+00:00, 2022-07-09 13:41:45...</td>\n",
              "      <td>b'Piece of Peace \\n\\xe2\\x9c\\x8c\\xf0\\x9f\\x8f\\xb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-07-08 13:01:38+00:00, 2022-06-29 07:30:54...</td>\n",
              "      <td>b'The @Wimbledon Virtual Hill, presented by @A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-11-02 16:02:32+00:00, 2017-10-03 17:44:35...</td>\n",
              "      <td>b'I like u so much more than your social media...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-07-09 18:49:52+00:00, 2022-07-09 05:37:33...</td>\n",
              "      <td>b'Kansas City!! \\xf0\\x9f\\x96\\xa4\\xf0\\x9f\\xa7\\x...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2021-09-26 11:22:32+00:00, 2021-09-25 16:13:04...</td>\n",
              "      <td>b'RT @IATSE: We are fighting to ensure that th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2022-07-03 04:33:48+00:00, 2022-07-01 14:51:06...</td>\n",
              "      <td>b'\\xf0\\x9f\\x98\\x82\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2022-07-11 05:49:21+00:00, 2022-07-11 05:18:22...</td>\n",
              "      <td>b'RT @0918cst___: The video, lighting, venue, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2022-05-26 03:57:33+00:00, 2022-05-26 03:57:24...</td>\n",
              "      <td>b'RT @gofundme: To support those affected by t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>2022-07-11 19:06:39+00:00, 2022-07-08 18:43:08...</td>\n",
              "      <td>b'When you hear someone open a bag of chips ht...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  date  \\\n",
              "0    2021-08-20 17:22:27+00:00, 2021-08-06 18:02:13...   \n",
              "1    2022-07-10 20:14:18+00:00, 2022-07-09 13:41:45...   \n",
              "2    2022-07-08 13:01:38+00:00, 2022-06-29 07:30:54...   \n",
              "3    2018-11-02 16:02:32+00:00, 2017-10-03 17:44:35...   \n",
              "4    2022-07-09 18:49:52+00:00, 2022-07-09 05:37:33...   \n",
              "..                                                 ...   \n",
              "96   2021-09-26 11:22:32+00:00, 2021-09-25 16:13:04...   \n",
              "97   2022-07-03 04:33:48+00:00, 2022-07-01 14:51:06...   \n",
              "98   2022-07-11 05:49:21+00:00, 2022-07-11 05:18:22...   \n",
              "99   2022-05-26 03:57:33+00:00, 2022-05-26 03:57:24...   \n",
              "100  2022-07-11 19:06:39+00:00, 2022-07-08 18:43:08...   \n",
              "\n",
              "                                                 tweet  \n",
              "0    b'Puppies and music \\xe2\\x80\\x94 just the thin...  \n",
              "1    b'Piece of Peace \\n\\xe2\\x9c\\x8c\\xf0\\x9f\\x8f\\xb...  \n",
              "2    b'The @Wimbledon Virtual Hill, presented by @A...  \n",
              "3    b'I like u so much more than your social media...  \n",
              "4    b'Kansas City!! \\xf0\\x9f\\x96\\xa4\\xf0\\x9f\\xa7\\x...  \n",
              "..                                                 ...  \n",
              "96   b'RT @IATSE: We are fighting to ensure that th...  \n",
              "97   b'\\xf0\\x9f\\x98\\x82\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f...  \n",
              "98   b'RT @0918cst___: The video, lighting, venue, ...  \n",
              "99   b'RT @gofundme: To support those affected by t...  \n",
              "100  b'When you hear someone open a bag of chips ht...  \n",
              "\n",
              "[101 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweet_data_copy = tweet_data.copy()\n",
        "tweet_data_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ycAbfuftIP8w"
      },
      "outputs": [],
      "source": [
        "def processEmoji(data):\n",
        "  for i in range(len(data)):\n",
        "    post = data.at[i, 'tweet']\n",
        "    result = re.findall(r'\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]\\\\x[0-9][0-9]\\\\x[A-Za-z][0-9]\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]\\\\x[0-9][0-9]\\\\x[A-Za-z][0-9]|\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]\\\\x[0-9][A-Za-z]\\\\x[A-Za-z][0-9]|\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]\\\\x[0-9][0-9]\\\\x[A-Za-z][0-9]|\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]\\\\x[0-9][0-9]\\\\x[0-9][0-9]|\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]|\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]\\\\x[0-9][0-9]\\\\x[0-9][A-Za-z]|\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]\\\\x[0-9][0-9]\\\\x[A-Za-z][A-Za-z]|\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]\\\\x[A-Za-z][0-9]\\\\x[A-Za-z][0-9]|\\\\x[A-Za-z][0-9]\\\\x[0-9][0-9]\\\\x[0-9][0-9]|\\\\x[A-Za-z][0-9]\\\\x[0-9][0-9]\\\\x[A-Za-z][0-9]\\\\x[A-Za-z][A-Za-z]\\\\x[A-Za-z][0-9]\\\\x[0-9][A-Za-z]|\\\\x[A-Za-z][0-9]\\\\x[0-9][0-9]\\\\x[0-9][A-Za-z]', post)\n",
        "    string_ = []\n",
        "    for j in result:\n",
        "      string_.append(j.encode().decode('unicode_escape').encode(\"raw_unicode_escape\"))\n",
        "    emoji_list = []\n",
        "    for k in string_:\n",
        "      emoji_list.append(k.decode(\"utf-8\", errors='ignore'))\n",
        "    emoji_text = []\n",
        "    for m in range(len(emoji_list)):\n",
        "      emoji_text.append(emoji.demojize(emoji_list[m]))\n",
        "    post_list = []\n",
        "    for l in range(len(result)):\n",
        "      post = post.replace(result[l] , emoji_text[l])\n",
        "    data.tweet[i] = post\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "UFLohtxcgCmY",
        "outputId": "78ac1e98-4ad7-401e-a279-3b48da8bbfa4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-08-20 17:22:27+00:00, 2021-08-06 18:02:13...</td>\n",
              "      <td>b'Puppies and music — just the thing to put yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-07-10 20:14:18+00:00, 2022-07-09 13:41:45...</td>\n",
              "      <td>b'Piece of Peace \\n:victory_hand:\\x9f\\x8f\\xbdo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-07-08 13:01:38+00:00, 2022-06-29 07:30:54...</td>\n",
              "      <td>b'The @Wimbledon Virtual Hill, presented by @A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-11-02 16:02:32+00:00, 2017-10-03 17:44:35...</td>\n",
              "      <td>b'I like u so much more than your social media...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-07-09 18:49:52+00:00, 2022-07-09 05:37:33...</td>\n",
              "      <td>b'Kansas City!! :black_heart::orange_heart: ht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2021-09-26 11:22:32+00:00, 2021-09-25 16:13:04...</td>\n",
              "      <td>b'RT @IATSE: We are fighting to ensure that th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2022-07-03 04:33:48+00:00, 2022-07-01 14:51:06...</td>\n",
              "      <td>b':face_with_tears_of_joy:\\xf0\\x9f\\xa4\\x98\\xf0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2022-07-11 05:49:21+00:00, 2022-07-11 05:18:22...</td>\n",
              "      <td>b'RT @0918cst___: The video, lighting, venue, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2022-05-26 03:57:33+00:00, 2022-05-26 03:57:24...</td>\n",
              "      <td>b'RT @gofundme: To support those affected by t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>2022-07-11 19:06:39+00:00, 2022-07-08 18:43:08...</td>\n",
              "      <td>b'When you hear someone open a bag of chips ht...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  date  \\\n",
              "0    2021-08-20 17:22:27+00:00, 2021-08-06 18:02:13...   \n",
              "1    2022-07-10 20:14:18+00:00, 2022-07-09 13:41:45...   \n",
              "2    2022-07-08 13:01:38+00:00, 2022-06-29 07:30:54...   \n",
              "3    2018-11-02 16:02:32+00:00, 2017-10-03 17:44:35...   \n",
              "4    2022-07-09 18:49:52+00:00, 2022-07-09 05:37:33...   \n",
              "..                                                 ...   \n",
              "96   2021-09-26 11:22:32+00:00, 2021-09-25 16:13:04...   \n",
              "97   2022-07-03 04:33:48+00:00, 2022-07-01 14:51:06...   \n",
              "98   2022-07-11 05:49:21+00:00, 2022-07-11 05:18:22...   \n",
              "99   2022-05-26 03:57:33+00:00, 2022-05-26 03:57:24...   \n",
              "100  2022-07-11 19:06:39+00:00, 2022-07-08 18:43:08...   \n",
              "\n",
              "                                                 tweet  \n",
              "0    b'Puppies and music — just the thing to put yo...  \n",
              "1    b'Piece of Peace \\n:victory_hand:\\x9f\\x8f\\xbdo...  \n",
              "2    b'The @Wimbledon Virtual Hill, presented by @A...  \n",
              "3    b'I like u so much more than your social media...  \n",
              "4    b'Kansas City!! :black_heart::orange_heart: ht...  \n",
              "..                                                 ...  \n",
              "96   b'RT @IATSE: We are fighting to ensure that th...  \n",
              "97   b':face_with_tears_of_joy:\\xf0\\x9f\\xa4\\x98\\xf0...  \n",
              "98   b'RT @0918cst___: The video, lighting, venue, ...  \n",
              "99   b'RT @gofundme: To support those affected by t...  \n",
              "100  b'When you hear someone open a bag of chips ht...  \n",
              "\n",
              "[101 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_emoji = processEmoji(tweet_data_copy)\n",
        "processed_emoji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 處理文字"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rIme4VV_OAZ1"
      },
      "outputs": [],
      "source": [
        "def Preprocessor_tweet(text:str, remove_mbti: bool=True) -> list:\n",
        "\t# Cleaning\n",
        "\ttext = re.sub(r'\\|\\|\\|', ' ', text)  # Split by separator\n",
        "\ttext = re.sub(r'http\\S+', ' ', text)  # Replace hyperlink\n",
        "\ttext = re.sub(r'\\d',' ', text)  # Remove digits\n",
        "\ttext = re.sub(r'^b\\'', ' ', text)  # Remove b' (某些post開頭會出現)\n",
        "\ttext = re.sub(r\"[A-Za-z]+\\'+\\w+\", ' ', text)  # Handling apostrophe (e.g. you've, there's)\n",
        "\ttext = re.sub(r'x[A-Za-z]', ' ', text)  # Remove unicode\n",
        "\ttext = re.sub(r'\\b[A-Za-z]\\b', ' ', text)  # Remove single letter\n",
        "\ttext = re.sub(r\"\\@+[A-Za-z]+\\w+\", ' ', text)  # Remove user name\n",
        "\ttext = re.sub(r'\\bR[A-Z]\\b', ' ', text)  # Remove 轉發符號\n",
        "\ttext = re.sub(r'[.,\"\\'\\-\\+\\[\\]?:!;@#&()]', ' ', text)  # Remove punctuation\n",
        "\ttext = re.sub(r'\\\\',' ', text)  # Remove punctuation\n",
        "\ttext = re.sub(r'[’“”/]', ' ', text)  # Remove punctuation\n",
        "\ttext = text.lower()\n",
        "\tif remove_mbti == True:\n",
        "\t\ttext = re.sub('intj|intp|entj|entp|infp|enfj|enfp|istj|isfj|estj|esfj|istp|isfp|estp|esfp|infj', '', text)\n",
        "\t# Tokenization\n",
        "\ttokens = word_tokenize(text)\n",
        "\tfiltered_tokens = [w for w in tokens if not w in stopwords.words('english')]  # Remove stopwords\n",
        "\t# Stemming\n",
        "\tstemmer_ = SnowballStemmer(\"english\")\n",
        "\tstemmed = [stemmer_.stem(t) for t in filtered_tokens]\n",
        "\t# Lemmatizing\n",
        "\tlemma = WordNetLemmatizer()\n",
        "\tlemmatized = \" \".join([lemma.lemmatize(w) for w in stemmed])\n",
        "\treturn lemmatized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_emoji_ = processed_emoji.copy()\n",
        "processed_emoji_['clean'] = processed_emoji_['tweet'].apply(Preprocessor_tweet, remove_mbti=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge celebrity MBTI label and tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name_in_tweetcel</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adamlevine</td>\n",
              "      <td>ESFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aliciakeys</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>andy_murray</td>\n",
              "      <td>ISTP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AnselElgort</td>\n",
              "      <td>ENFJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AvrilLavigne</td>\n",
              "      <td>ISFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>ZacEfron</td>\n",
              "      <td>ISFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>zaynmalik</td>\n",
              "      <td>ISFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Zedd</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Zendaya</td>\n",
              "      <td>INFJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>ZooeyDeschanel</td>\n",
              "      <td>ENFP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    name_in_tweetcel  type\n",
              "0         adamlevine  ESFP\n",
              "1         aliciakeys  INFP\n",
              "2        andy_murray  ISTP\n",
              "3        AnselElgort  ENFJ\n",
              "4       AvrilLavigne  ISFP\n",
              "..               ...   ...\n",
              "96          ZacEfron  ISFP\n",
              "97         zaynmalik  ISFP\n",
              "98              Zedd  INTJ\n",
              "99           Zendaya  INFJ\n",
              "100   ZooeyDeschanel  ENFP\n",
              "\n",
              "[101 rows x 2 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweet_y = pd.read_csv('../data/celebrityMBTI.csv')\n",
        "tweet_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name_in_tweetcel</th>\n",
              "      <th>type</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adamlevine</td>\n",
              "      <td>ESFP</td>\n",
              "      <td>puppi music — thing put good mood play theatr ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aliciakeys</td>\n",
              "      <td>INFP</td>\n",
              "      <td>piec peac victory_hand dof soulcaresunday remi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>andy_murray</td>\n",
              "      <td>ISTP</td>\n",
              "      <td>virtual hill present allow fan sit hill creat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AnselElgort</td>\n",
              "      <td>ENFJ</td>\n",
              "      <td>like much social medium presenc autocorrect co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AvrilLavigne</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>kansa citi black_heart orange_heart lie nreven...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>ZacEfron</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>fight ensur power medium corpor planet treat f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>zaynmalik</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>face_with_tears_of_joy come brav ufc love supp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Zedd</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>cst___ video light venu everyth power realli a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Zendaya</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>support affect elementari school shoot uvald t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>ZooeyDeschanel</td>\n",
              "      <td>ENFP</td>\n",
              "      <td>hear someon open bag chip year marriag handsom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    name_in_tweetcel  type                                              clean\n",
              "0         adamlevine  ESFP  puppi music — thing put good mood play theatr ...\n",
              "1         aliciakeys  INFP  piec peac victory_hand dof soulcaresunday remi...\n",
              "2        andy_murray  ISTP  virtual hill present allow fan sit hill creat ...\n",
              "3        AnselElgort  ENFJ  like much social medium presenc autocorrect co...\n",
              "4       AvrilLavigne  ISFP  kansa citi black_heart orange_heart lie nreven...\n",
              "..               ...   ...                                                ...\n",
              "96          ZacEfron  ISFP  fight ensur power medium corpor planet treat f...\n",
              "97         zaynmalik  ISFP  face_with_tears_of_joy come brav ufc love supp...\n",
              "98              Zedd  INTJ  cst___ video light venu everyth power realli a...\n",
              "99           Zendaya  INFJ  support affect elementari school shoot uvald t...\n",
              "100   ZooeyDeschanel  ENFP  hear someon open bag chip year marriag handsom...\n",
              "\n",
              "[101 rows x 3 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "twitter = pd.concat([tweet_y, processed_emoji_['clean']], axis = 1)\n",
        "twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check non-English corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name_in_tweetcel</th>\n",
              "      <th>type</th>\n",
              "      <th>clean</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>LuisSuarez9</td>\n",
              "      <td>ESFP</td>\n",
              "      <td>love time de papi tu felicidad e mi felicidad ...</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>RafaelNadal</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>never held racket felt everi shot piec journey...</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>ricky_martin</td>\n",
              "      <td>ESFP</td>\n",
              "      <td>ship independ day nend u standard photo littl ...</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   name_in_tweetcel  type                                              clean  \\\n",
              "52      LuisSuarez9  ESFP  love time de papi tu felicidad e mi felicidad ...   \n",
              "62      RafaelNadal  ISFP  never held racket felt everi shot piec journey...   \n",
              "65     ricky_martin  ESFP  ship independ day nend u standard photo littl ...   \n",
              "\n",
              "   lang  \n",
              "52   es  \n",
              "62   es  \n",
              "65   es  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langdetect import detect\n",
        "twitter['lang'] = twitter['clean'].apply(lambda x: detect(x))\n",
        "twitter[twitter['lang'] != 'en']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(98, 3)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop the non-English corpus\n",
        "twitter = twitter[twitter['lang'] == 'en'].drop(columns='lang')\n",
        "twitter.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "twitter.to_csv('../data/twitter_1205.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge Kaggle and Twitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "V_zVzg8S69oL",
        "outputId": "9c319104-6f15-4b44-d788-ac3ee8d8665d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>flat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>moment sportscent top ten play prank life chan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>find lack post alarm sex bore posit often exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>good one cours say know bless cur absolut posi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>dear enjoy convers day esoter gab natur univer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8670</th>\n",
              "      <td>ISFP</td>\n",
              "      <td>ixfp alway think cat fi dom reason especi webs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8671</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>thread alreadi exist someplac el heck delet on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8672</th>\n",
              "      <td>INTP</td>\n",
              "      <td>mani question thing would take purpl pill pick...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8673</th>\n",
              "      <td>INFP</td>\n",
              "      <td>conflict right come want child honest matern i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>INFP</td>\n",
              "      <td>long sinc personalitycaf although seem chang o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8675 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               flat\n",
              "0     INFJ  moment sportscent top ten play prank life chan...\n",
              "1     ENTP  find lack post alarm sex bore posit often exam...\n",
              "2     INTP  good one cours say know bless cur absolut posi...\n",
              "3     INTJ  dear enjoy convers day esoter gab natur univer...\n",
              "4     ENTJ  fire anoth silli misconcept approach logic go ...\n",
              "...    ...                                                ...\n",
              "8670  ISFP  ixfp alway think cat fi dom reason especi webs...\n",
              "8671  ENFP  thread alreadi exist someplac el heck delet on...\n",
              "8672  INTP  mani question thing would take purpl pill pick...\n",
              "8673  INFP  conflict right come want child honest matern i...\n",
              "8674  INFP  long sinc personalitycaf although seem chang o...\n",
              "\n",
              "[8675 rows x 2 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kaggle = pd.read_csv('../data/Kaggle_MBTI_newPre.csv').drop(['posts','preprocessed'],axis=1)\n",
        "kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "twitter = twitter.rename(columns = {'clean':'flat'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "s1tucvBnsAt5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>flat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>moment sportscent top ten play prank life chan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>find lack post alarm sex bore posit often exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>good one cours say know bless cur absolut posi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>dear enjoy convers day esoter gab natur univer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8767</th>\n",
              "      <td>ISFP</td>\n",
              "      <td>fight ensur power medium corpor planet treat f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8768</th>\n",
              "      <td>ISFP</td>\n",
              "      <td>face_with_tears_of_joy come brav ufc love supp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8769</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>cst___ video light venu everyth power realli a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8770</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>support affect elementari school shoot uvald t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8771</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>hear someon open bag chip year marriag handsom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8772 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               flat\n",
              "0     INFJ  moment sportscent top ten play prank life chan...\n",
              "1     ENTP  find lack post alarm sex bore posit often exam...\n",
              "2     INTP  good one cours say know bless cur absolut posi...\n",
              "3     INTJ  dear enjoy convers day esoter gab natur univer...\n",
              "4     ENTJ  fire anoth silli misconcept approach logic go ...\n",
              "...    ...                                                ...\n",
              "8767  ISFP  fight ensur power medium corpor planet treat f...\n",
              "8768  ISFP  face_with_tears_of_joy come brav ufc love supp...\n",
              "8769  INTJ  cst___ video light venu everyth power realli a...\n",
              "8770  INFJ  support affect elementari school shoot uvald t...\n",
              "8771  ENFP  hear someon open bag chip year marriag handsom...\n",
              "\n",
              "[8772 rows x 2 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kaggle_twitter = pd.concat([kaggle, twitter[['type','flat']]]).dropna().reset_index(drop=True)\n",
        "kaggle_twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "由於 twitter 資料在最後面，用 Shuffle 打亂"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>flat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>deal dr doorslam overreact one someon life dep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>sound like typic trait role se h fe lack ethic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INFP</td>\n",
              "      <td>coach biggest person nfl rex ryan think evil o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INFP</td>\n",
              "      <td>haha wow interest sure yeah guess ok pixi time...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>know hate anyway rack disprin gon na play vide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8767</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>correct went troubl becom dish end irrespect d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8768</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>trick know valu know passion find group peopl ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8769</th>\n",
              "      <td>INFP</td>\n",
              "      <td>ok talk friend age lot late go pose question f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8770</th>\n",
              "      <td>INFP</td>\n",
              "      <td>even loner get lone feel like hard hard relati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8771</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>mayb pattern beg explan realli care understand...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8772 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               flat\n",
              "0     INFJ  deal dr doorslam overreact one someon life dep...\n",
              "1     ENTP  sound like typic trait role se h fe lack ethic...\n",
              "2     INFP  coach biggest person nfl rex ryan think evil o...\n",
              "3     INFP  haha wow interest sure yeah guess ok pixi time...\n",
              "4     ENTP  know hate anyway rack disprin gon na play vide...\n",
              "...    ...                                                ...\n",
              "8767  INFJ  correct went troubl becom dish end irrespect d...\n",
              "8768  ENFP  trick know valu know passion find group peopl ...\n",
              "8769  INFP  ok talk friend age lot late go pose question f...\n",
              "8770  INFP  even loner get lone feel like hard hard relati...\n",
              "8771  INTJ  mayb pattern beg explan realli care understand...\n",
              "\n",
              "[8772 rows x 2 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shuffle = kaggle_twitter.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "shuffle.to_csv('../data/kaggle+twitter.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('chung777')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0514e5c77cd99cf9fa7b373475c6e75ef091a76b518b05acebede09ef4510bce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
