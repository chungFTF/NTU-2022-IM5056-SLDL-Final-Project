{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>flat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>moment sportscent top ten play prank life chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>find lack post alarm sex bore posit often exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>good one cours say know bless cur absolut posi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear enjoy convers day esoter gab natur univer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>8771</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>fight ensur power medium corpor planet treat f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>8772</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>face_with_tears_of_joy sign_of_the_horns_mediu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8773</th>\n",
       "      <td>8773</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>cst___ video light venu everyth power realli a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>8774</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>support affect elementari school shoot uvald t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>8775</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>hear someon open bag chip year marriag handsom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8776 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  type                                               flat\n",
       "0              0  INFJ  moment sportscent top ten play prank life chan...\n",
       "1              1  ENTP  find lack post alarm sex bore posit often exam...\n",
       "2              2  INTP  good one cours say know bless cur absolut posi...\n",
       "3              3  INTJ  dear enjoy convers day esoter gab natur univer...\n",
       "4              4  ENTJ  fire anoth silli misconcept approach logic go ...\n",
       "...          ...   ...                                                ...\n",
       "8771        8771  ISFP  fight ensur power medium corpor planet treat f...\n",
       "8772        8772  ISFP  face_with_tears_of_joy sign_of_the_horns_mediu...\n",
       "8773        8773  INTJ  cst___ video light venu everyth power realli a...\n",
       "8774        8774  INFJ  support affect elementari school shoot uvald t...\n",
       "8775        8775  ENFP  hear someon open bag chip year marriag handsom...\n",
       "\n",
       "[8776 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = pd.read_csv('../../data/kaggle+twitter.csv')\n",
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posts = []\n",
    "for i in range(len(trainset)):\n",
    "    post = trainset.loc[i, 'flat']\n",
    "    list_posts.append(post)\n",
    "list_posts = np.array(list_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CountVectorizer :\n",
      "\n",
      "Using Tf-idf :\n",
      "Now the dataset size is as below\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8776, 132543)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorizing the database posts to a matrix of token counts for the model\n",
    "cntizer = CountVectorizer() \n",
    "                        \n",
    "# the feature should be made of word n-gram \n",
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "print(\"Using CountVectorizer :\")\n",
    "X_cnt = cntizer.fit_transform(list_posts)\n",
    "col_name = cntizer.get_feature_names_out()   # 紀錄 sparse matrix 的字分別是哪些字\n",
    "\n",
    "\n",
    "# For the Standardization or Feature Scaling Stage :-\n",
    "# Transform the count matrix to a normalized tf or tf-idf representation\n",
    "tfizer = TfidfTransformer()\n",
    "\n",
    "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
    "print(\"\\nUsing Tf-idf :\")\n",
    "\n",
    "print(\"Now the dataset size is as below\")\n",
    "X_tfidf =  tfizer.fit_transform(X_cnt).toarray()\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.29552665e-01, -2.89886743e-02, -4.59738607e-02, ...,\n",
       "        -1.66633285e-03, -1.23848509e-02, -1.09445092e-02],\n",
       "       [ 3.60625669e-01,  1.24753477e-02, -3.40479105e-04, ...,\n",
       "         3.73606198e-03, -8.52255963e-03, -2.89700568e-02],\n",
       "       [ 3.27324445e-01, -3.09335700e-02, -4.04488445e-02, ...,\n",
       "        -1.41624581e-02, -3.70646609e-02,  2.24247394e-02],\n",
       "       ...,\n",
       "       [ 2.15979990e-01, -7.89459044e-02, -2.60553941e-02, ...,\n",
       "         2.98201630e-02,  7.92356995e-03, -3.36127923e-02],\n",
       "       [ 1.90536688e-01, -9.16637045e-02, -9.06452688e-03, ...,\n",
       "         3.78216694e-02,  1.29135565e-02, -1.68493310e-02],\n",
       "       [ 2.57942925e-01, -1.32508831e-01, -2.37310305e-02, ...,\n",
       "        -1.95025416e-02, -1.53650549e-02,  2.66041597e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "result = svd.fit_transform(X_tfidf)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229553</td>\n",
       "      <td>-0.028989</td>\n",
       "      <td>-0.045974</td>\n",
       "      <td>0.066428</td>\n",
       "      <td>-0.057229</td>\n",
       "      <td>0.079087</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.032540</td>\n",
       "      <td>-0.009948</td>\n",
       "      <td>0.038943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>-0.008046</td>\n",
       "      <td>-0.029300</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>0.020756</td>\n",
       "      <td>0.060105</td>\n",
       "      <td>-0.030927</td>\n",
       "      <td>-0.001666</td>\n",
       "      <td>-0.012385</td>\n",
       "      <td>-0.010945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360626</td>\n",
       "      <td>0.012475</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>0.022319</td>\n",
       "      <td>-0.006080</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>-0.060051</td>\n",
       "      <td>-0.010684</td>\n",
       "      <td>-0.040281</td>\n",
       "      <td>-0.011646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>0.043186</td>\n",
       "      <td>0.026046</td>\n",
       "      <td>0.021477</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>-0.027270</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>-0.008523</td>\n",
       "      <td>-0.028970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327324</td>\n",
       "      <td>-0.030934</td>\n",
       "      <td>-0.040449</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>-0.027835</td>\n",
       "      <td>0.053572</td>\n",
       "      <td>-0.016258</td>\n",
       "      <td>-0.024198</td>\n",
       "      <td>-0.007088</td>\n",
       "      <td>-0.001764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020128</td>\n",
       "      <td>-0.041694</td>\n",
       "      <td>-0.038324</td>\n",
       "      <td>-0.030900</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>-0.024744</td>\n",
       "      <td>-0.012335</td>\n",
       "      <td>-0.014162</td>\n",
       "      <td>-0.037065</td>\n",
       "      <td>0.022425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.386935</td>\n",
       "      <td>0.149640</td>\n",
       "      <td>-0.024360</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>-0.044892</td>\n",
       "      <td>-0.022475</td>\n",
       "      <td>0.024637</td>\n",
       "      <td>0.058961</td>\n",
       "      <td>0.065796</td>\n",
       "      <td>-0.054293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>-0.035642</td>\n",
       "      <td>-0.016188</td>\n",
       "      <td>-0.003154</td>\n",
       "      <td>0.017735</td>\n",
       "      <td>-0.019992</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>-0.001379</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.028174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311357</td>\n",
       "      <td>-0.012648</td>\n",
       "      <td>-0.029454</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-0.058061</td>\n",
       "      <td>-0.068007</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>0.038274</td>\n",
       "      <td>-0.059952</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016169</td>\n",
       "      <td>0.027091</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>0.017459</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-0.007075</td>\n",
       "      <td>-0.010500</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.006893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>0.145925</td>\n",
       "      <td>-0.076368</td>\n",
       "      <td>-0.018983</td>\n",
       "      <td>0.087965</td>\n",
       "      <td>-0.055252</td>\n",
       "      <td>0.158276</td>\n",
       "      <td>-0.065960</td>\n",
       "      <td>-0.140311</td>\n",
       "      <td>0.064631</td>\n",
       "      <td>-0.060026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.023920</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>-0.015666</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.008782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>0.309016</td>\n",
       "      <td>-0.162717</td>\n",
       "      <td>0.062645</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>-0.051515</td>\n",
       "      <td>0.229390</td>\n",
       "      <td>-0.076628</td>\n",
       "      <td>-0.190612</td>\n",
       "      <td>0.077283</td>\n",
       "      <td>-0.136714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034406</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>-0.026552</td>\n",
       "      <td>0.023591</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>-0.005890</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>0.025508</td>\n",
       "      <td>0.020339</td>\n",
       "      <td>-0.009905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8773</th>\n",
       "      <td>0.215980</td>\n",
       "      <td>-0.078946</td>\n",
       "      <td>-0.026055</td>\n",
       "      <td>0.103513</td>\n",
       "      <td>-0.076049</td>\n",
       "      <td>0.146495</td>\n",
       "      <td>-0.085867</td>\n",
       "      <td>-0.130801</td>\n",
       "      <td>0.047882</td>\n",
       "      <td>-0.072179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025495</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>-0.024358</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.029820</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>-0.033613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>0.190537</td>\n",
       "      <td>-0.091664</td>\n",
       "      <td>-0.009065</td>\n",
       "      <td>0.090745</td>\n",
       "      <td>-0.065706</td>\n",
       "      <td>0.151323</td>\n",
       "      <td>-0.076247</td>\n",
       "      <td>-0.135038</td>\n",
       "      <td>0.059777</td>\n",
       "      <td>-0.093521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035706</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.016421</td>\n",
       "      <td>0.019765</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>-0.020577</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.037822</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>-0.016849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>0.257943</td>\n",
       "      <td>-0.132509</td>\n",
       "      <td>-0.023731</td>\n",
       "      <td>0.106114</td>\n",
       "      <td>-0.050041</td>\n",
       "      <td>0.209582</td>\n",
       "      <td>-0.094936</td>\n",
       "      <td>-0.147726</td>\n",
       "      <td>0.071301</td>\n",
       "      <td>-0.057039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026740</td>\n",
       "      <td>-0.023886</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>-0.021123</td>\n",
       "      <td>-0.024248</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.019503</td>\n",
       "      <td>-0.015365</td>\n",
       "      <td>0.026604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8776 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.229553 -0.028989 -0.045974  0.066428 -0.057229  0.079087  0.003797   \n",
       "1     0.360626  0.012475 -0.000340  0.022319 -0.006080  0.034986 -0.060051   \n",
       "2     0.327324 -0.030934 -0.040449  0.026471 -0.027835  0.053572 -0.016258   \n",
       "3     0.386935  0.149640 -0.024360  0.000873 -0.044892 -0.022475  0.024637   \n",
       "4     0.311357 -0.012648 -0.029454  0.000107 -0.058061 -0.068007  0.012177   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8771  0.145925 -0.076368 -0.018983  0.087965 -0.055252  0.158276 -0.065960   \n",
       "8772  0.309016 -0.162717  0.062645  0.110800 -0.051515  0.229390 -0.076628   \n",
       "8773  0.215980 -0.078946 -0.026055  0.103513 -0.076049  0.146495 -0.085867   \n",
       "8774  0.190537 -0.091664 -0.009065  0.090745 -0.065706  0.151323 -0.076247   \n",
       "8775  0.257943 -0.132509 -0.023731  0.106114 -0.050041  0.209582 -0.094936   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     0.032540 -0.009948  0.038943  ...  0.002499 -0.008046 -0.029300   \n",
       "1    -0.010684 -0.040281 -0.011646  ... -0.000149  0.043186  0.026046   \n",
       "2    -0.024198 -0.007088 -0.001764  ...  0.020128 -0.041694 -0.038324   \n",
       "3     0.058961  0.065796 -0.054293  ... -0.001368 -0.035642 -0.016188   \n",
       "4     0.038274 -0.059952 -0.069083  ... -0.016169  0.027091 -0.004162   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "8771 -0.140311  0.064631 -0.060026  ...  0.007848 -0.014100  0.002095   \n",
       "8772 -0.190612  0.077283 -0.136714  ...  0.034406  0.015390 -0.026552   \n",
       "8773 -0.130801  0.047882 -0.072179  ... -0.025495  0.000020  0.017968   \n",
       "8774 -0.135038  0.059777 -0.093521  ... -0.035706  0.005411  0.016421   \n",
       "8775 -0.147726  0.071301 -0.057039  ...  0.026740 -0.023886  0.007499   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.010658  0.020756  0.060105 -0.030927 -0.001666 -0.012385 -0.010945  \n",
       "1     0.021477  0.016897 -0.025803 -0.027270  0.003736 -0.008523 -0.028970  \n",
       "2    -0.030900  0.012010 -0.024744 -0.012335 -0.014162 -0.037065  0.022425  \n",
       "3    -0.003154  0.017735 -0.019992  0.013362 -0.001379  0.006080  0.028174  \n",
       "4     0.017459 -0.003076 -0.007075 -0.010500 -0.002241  0.003513  0.006893  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "8771  0.023920  0.001678  0.007000 -0.015666  0.005461  0.008498  0.008782  \n",
       "8772  0.023591  0.016340 -0.005890  0.012111  0.025508  0.020339 -0.009905  \n",
       "8773  0.008183  0.012583 -0.024358  0.005259  0.029820  0.007924 -0.033613  \n",
       "8774  0.019765  0.038883 -0.020577  0.000425  0.037822  0.012914 -0.016849  \n",
       "8775 -0.021123 -0.024248  0.005490 -0.006634 -0.019503 -0.015365  0.026604  \n",
       "\n",
       "[8776 rows x 100 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdf = pd.DataFrame(result)\n",
    "trainingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data = raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenenying/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimator = 100, learning_rate = 0.18, best accuracy = 0.3279254401104591 \n",
      "n_estimator = 200, learning_rate = 0.12, best accuracy = 0.3341387642388678 \n",
      "n_estimator = 300, learning_rate = 0.12, best accuracy = 0.33551950293406974 \n",
      "n_estimator = 400, learning_rate = 0.12, best accuracy = 0.33931653434587505 \n",
      "n_estimator = 500, learning_rate = 0.15, best accuracy = 0.3403520883672765 \n",
      "n_estimator = 600, learning_rate = 0.1, best accuracy = 0.33897134967207454 \n",
      "n_estimator = 700, learning_rate = 0.1, best accuracy = 0.33724542630307214 \n",
      "n_estimator = 800, learning_rate = 0.1, best accuracy = 0.3341387642388678 \n",
      "n_estimator = 900, learning_rate = 0.1, best accuracy = 0.3334483948912668 \n",
      "n_estimator = 1000, learning_rate = 0.12, best accuracy = 0.3324128408698654 \n",
      "Result : best n_estimator = 500, best learning_rate = 0.15, best accuracy = 0.3403520883672765 \n",
      "-----------------------------------------------------------\n",
      "Accuracy: 34.04%\n",
      "Micro Precision: 34.04%\n",
      "Macro Precision: 22.57%\n",
      "Micro Recall: 34.04%\n",
      "Macro Recall: 17.29%\n",
      "Micro F1score: 34.04%\n",
      "Macro F1score: 17.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenenying/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "label = trainset.loc[:,['type']]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Y = LabelEncoder().fit_transform(label)   # Y before train-test-split\n",
    "\n",
    "# train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(trainingdf, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# grid search\n",
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=1000, num=10)]\n",
    "learning_rate=[round(float(x),2) for x in np.linspace(start=0.1, stop=0.2, num=5)]\n",
    "\n",
    "best_nest = 0\n",
    "best_lr = 0\n",
    "best_acc=0\n",
    "\n",
    "for nest in n_estimators:\n",
    "    local_acc = 0\n",
    "    local_lr = 0\n",
    "    for lr in learning_rate:\n",
    "        param = {}\n",
    "        param['n_estimators'] = nest\n",
    "        param['max_depth'] = 2\n",
    "        param['learning_rate'] = lr\n",
    "\n",
    "        xgb = XGBClassifier(**param)\n",
    "        xgb_model = xgb.fit(X_train,y_train)\n",
    "\n",
    "        Y_pred = xgb_model.predict(X_valid)\n",
    "        predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "        # evaluate predictions\n",
    "        accuracy = accuracy_score(y_valid, predictions)\n",
    "\n",
    "        if accuracy > local_acc:\n",
    "            local_acc = accuracy\n",
    "            local_lr = lr\n",
    "\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_nest = nest\n",
    "            best_lr = lr\n",
    "    \n",
    "    print(f'n_estimator = {nest}, learning_rate = {local_lr}, best accuracy = {local_acc} ')\n",
    "\n",
    "print(f'Result : best n_estimator = {best_nest}, best learning_rate = {best_lr}, best accuracy = {best_acc} ')\n",
    "print('-----------------------------------------------------------')\n",
    "\n",
    "\n",
    "#XG boost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "param = {}\n",
    "\n",
    "param['n_estimators'] = best_nest\n",
    "param['max_depth'] = 2\n",
    "param['learning_rate'] = best_lr\n",
    "\n",
    "xgb = XGBClassifier(**param)\n",
    "xgb_model = xgb.fit(X_train,y_train)\n",
    "\n",
    "Y_pred = xgb_model.predict(X_valid)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_valid, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "precision_mi = precision_score(y_valid, predictions, average='micro')\n",
    "print(\"Micro Precision: %.2f%%\" % (precision_mi * 100.0))\n",
    "precision_ma = precision_score(y_valid, predictions, average='macro')\n",
    "print(\"Macro Precision: %.2f%%\" % (precision_ma * 100.0))\n",
    "\n",
    "recall_mi = recall_score(y_valid, predictions, average='micro')\n",
    "print(\"Micro Recall: %.2f%%\" % (recall_mi * 100.0))\n",
    "recall_ma = recall_score(y_valid, predictions, average='macro')\n",
    "print(\"Macro Recall: %.2f%%\" % (recall_ma * 100.0))\n",
    "\n",
    "f1score_mi = f1_score(y_valid, predictions, average='micro')\n",
    "print(\"Micro F1score: %.2f%%\" % (f1score_mi * 100.0))\n",
    "f1score_ma = f1_score(y_valid, predictions, average='macro')\n",
    "print(\"Macro F1score: %.2f%%\" % (f1score_ma * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenenying/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimator = 100, learning_rate = 0.2, best accuracy = 0.26234035208836726 \n",
      "n_estimator = 200, learning_rate = 0.2, best accuracy = 0.28408698653779774 \n",
      "n_estimator = 300, learning_rate = 0.2, best accuracy = 0.2989299275112185 \n",
      "n_estimator = 400, learning_rate = 0.2, best accuracy = 0.3016914049016224 \n",
      "n_estimator = 500, learning_rate = 0.18, best accuracy = 0.30583362098722816 \n",
      "n_estimator = 600, learning_rate = 0.2, best accuracy = 0.30583362098722816 \n",
      "n_estimator = 700, learning_rate = 0.2, best accuracy = 0.3113565757680359 \n",
      "n_estimator = 800, learning_rate = 0.18, best accuracy = 0.3106662064204349 \n",
      "n_estimator = 900, learning_rate = 0.15, best accuracy = 0.3110113910942354 \n",
      "n_estimator = 1000, learning_rate = 0.12, best accuracy = 0.3161891612012427 \n",
      "Result : best n_estimator = 1000, best learning_rate = 0.12, best accuracy = 0.3161891612012427 \n",
      "-----------------------------------------------------------\n",
      "Result for XGboost after grid search (remove_MBTI = True, Model = XGboost, data = SMOTE)\n",
      "Accuracy: 31.62%\n",
      "Micro Precision: 31.62%\n",
      "Macro Precision: 20.91%\n",
      "Micro Recall: 31.62%\n",
      "Macro Recall: 20.55%\n",
      "Micro F1score: 31.62%\n",
      "Macro F1score: 20.52%\n"
     ]
    }
   ],
   "source": [
    "label = trainset.loc[:,['type']]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Y = LabelEncoder().fit_transform(label)   # Y before train-test-split\n",
    "\n",
    "# train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(trainingdf, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_re, y_re = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# grid search\n",
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=1000, num=10)]\n",
    "learning_rate=[round(float(x),2) for x in np.linspace(start=0.1, stop=0.2, num=5)]\n",
    "\n",
    "best_nest = 0\n",
    "best_lr = 0\n",
    "best_acc=0\n",
    "\n",
    "for nest in n_estimators:\n",
    "    local_acc = 0\n",
    "    local_lr = 0\n",
    "    for lr in learning_rate:\n",
    "        param = {}\n",
    "        param['n_estimators'] = nest\n",
    "        param['max_depth'] = 2\n",
    "        param['learning_rate'] = lr\n",
    "\n",
    "        xgb = XGBClassifier(**param)\n",
    "        xgb_model = xgb.fit(X_re,y_re)\n",
    "\n",
    "        Y_pred = xgb_model.predict(X_valid)\n",
    "        predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "        # evaluate predictions\n",
    "        accuracy = accuracy_score(y_valid, predictions)\n",
    "\n",
    "        if accuracy > local_acc:\n",
    "            local_acc = accuracy\n",
    "            local_lr = lr\n",
    "\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_nest = nest\n",
    "            best_lr = lr\n",
    "    \n",
    "    print(f'n_estimator = {nest}, learning_rate = {local_lr}, best accuracy = {local_acc} ')\n",
    "\n",
    "print(f'Result : best n_estimator = {best_nest}, best learning_rate = {best_lr}, best accuracy = {best_acc} ')\n",
    "print('-----------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "#XG boost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "param = {}\n",
    "\n",
    "param['n_estimators'] = best_nest # after tunning\n",
    "param['max_depth'] = 2\n",
    "param['learning_rate'] = best_lr # after tunning\n",
    "\n",
    "xgb = XGBClassifier(**param)\n",
    "xgb_model = xgb.fit(X_re, y_re)\n",
    "\n",
    "Y_pred = xgb_model.predict(X_valid)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "print('Result for XGboost after grid search (remove_MBTI = True, Model = XGboost, data = SMOTE)')\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_valid, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "precision_mi = precision_score(y_valid, predictions, average='micro')\n",
    "print(\"Micro Precision: %.2f%%\" % (precision_mi * 100.0))\n",
    "precision_ma = precision_score(y_valid, predictions, average='macro')\n",
    "print(\"Macro Precision: %.2f%%\" % (precision_ma * 100.0))\n",
    "\n",
    "recall_mi = recall_score(y_valid, predictions, average='micro')\n",
    "print(\"Micro Recall: %.2f%%\" % (recall_mi * 100.0))\n",
    "recall_ma = recall_score(y_valid, predictions, average='macro')\n",
    "print(\"Macro Recall: %.2f%%\" % (recall_ma * 100.0))\n",
    "\n",
    "f1score_mi = f1_score(y_valid, predictions, average='micro')\n",
    "print(\"Micro F1score: %.2f%%\" % (f1score_mi * 100.0))\n",
    "f1score_ma = f1_score(y_valid, predictions, average='macro')\n",
    "print(\"Macro F1score: %.2f%%\" % (f1score_ma * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine 4 binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>flat</th>\n",
       "      <th>IE</th>\n",
       "      <th>NS</th>\n",
       "      <th>TF</th>\n",
       "      <th>JP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>moment sportscent top ten play prank life chan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>find lack post alarm sex bore posit often exam...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>good one cours say know bless cur absolut posi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear enjoy convers day esoter gab natur univer...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>8771</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>fight ensur power medium corpor planet treat f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>8772</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>face_with_tears_of_joy sign_of_the_horns_mediu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8773</th>\n",
       "      <td>8773</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>cst___ video light venu everyth power realli a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>8774</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>support affect elementari school shoot uvald t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>8775</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>hear someon open bag chip year marriag handsom...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8776 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  type                                               flat  IE  \\\n",
       "0              0  INFJ  moment sportscent top ten play prank life chan...   1   \n",
       "1              1  ENTP  find lack post alarm sex bore posit often exam...   0   \n",
       "2              2  INTP  good one cours say know bless cur absolut posi...   1   \n",
       "3              3  INTJ  dear enjoy convers day esoter gab natur univer...   1   \n",
       "4              4  ENTJ  fire anoth silli misconcept approach logic go ...   0   \n",
       "...          ...   ...                                                ...  ..   \n",
       "8771        8771  ISFP  fight ensur power medium corpor planet treat f...   1   \n",
       "8772        8772  ISFP  face_with_tears_of_joy sign_of_the_horns_mediu...   1   \n",
       "8773        8773  INTJ  cst___ video light venu everyth power realli a...   1   \n",
       "8774        8774  INFJ  support affect elementari school shoot uvald t...   1   \n",
       "8775        8775  ENFP  hear someon open bag chip year marriag handsom...   0   \n",
       "\n",
       "      NS  TF  JP  \n",
       "0      1   0   1  \n",
       "1      1   1   0  \n",
       "2      1   1   0  \n",
       "3      1   1   1  \n",
       "4      1   1   1  \n",
       "...   ..  ..  ..  \n",
       "8771   0   0   0  \n",
       "8772   0   0   0  \n",
       "8773   1   1   1  \n",
       "8774   1   0   1  \n",
       "8775   1   0   0  \n",
       "\n",
       "[8776 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/kaggle+twitter.csv')\n",
    "def get_types(row):\n",
    "    t=row['type']\n",
    "\n",
    "    I = 0; N = 0\n",
    "    T = 0; J = 0\n",
    "    \n",
    "    if t[0] == 'I': I = 1\n",
    "    elif t[0] == 'E': I = 0\n",
    "    else: print('I-E not found') \n",
    "        \n",
    "    if t[1] == 'N': N = 1\n",
    "    elif t[1] == 'S': N = 0\n",
    "    else: print('N-S not found')\n",
    "        \n",
    "    if t[2] == 'T': T = 1\n",
    "    elif t[2] == 'F': T = 0\n",
    "    else: print('T-F not found')\n",
    "        \n",
    "    if t[3] == 'J': J = 1\n",
    "    elif t[3] == 'P': J = 0\n",
    "    else: print('J-P not found')\n",
    "    return pd.Series( {'IE':I, 'NS':N , 'TF': T, 'JP': J }) \n",
    "\n",
    "data = data.join(data.apply (lambda row: get_types (row),axis=1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introversion (I) /  Extroversion (E):\t 2057  /  6719\n",
      "Intuition (N) / Sensing (S):\t\t 1268  /  7508\n",
      "Thinking (T) / Feeling (F):\t\t 4757  /  4019\n",
      "Judging (J) / Perceiving (P):\t\t 5311  /  3465\n"
     ]
    }
   ],
   "source": [
    "print (\"Introversion (I) /  Extroversion (E):\\t\", data['IE'].value_counts()[0], \" / \", data['IE'].value_counts()[1])\n",
    "print (\"Intuition (N) / Sensing (S):\\t\\t\", data['NS'].value_counts()[0], \" / \", data['NS'].value_counts()[1])\n",
    "print (\"Thinking (T) / Feeling (F):\\t\\t\", data['TF'].value_counts()[0], \" / \", data['TF'].value_counts()[1])\n",
    "print (\"Judging (J) / Perceiving (P):\\t\\t\", data['JP'].value_counts()[0], \" / \", data['JP'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarize MBTI list: \n",
      "[[0 0 0 0]\n",
      " [1 0 1 1]\n",
      " [0 0 1 1]\n",
      " ...\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]\n",
      " [1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the MBTI personality into 4 letters and binarizing it\n",
    "\n",
    "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
    "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    return [b_Pers[l] for l in personality]\n",
    "\n",
    "#To show result output for personality prediction\n",
    "def translate_back(personality):\n",
    "    # transform binary vector to mbti personality\n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += b_Pers_list[i][l]\n",
    "    return s\n",
    "\n",
    "list_personality_bin = np.array([translate_personality(p) for p in data.type])\n",
    "print(\"Binarize MBTI list: \\n%s\" % list_personality_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8776, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_personality=[]\n",
    "for row in data.iterrows():\n",
    "    type_labelized = translate_personality(row[1].type) #or use lab_encoder.transform([row[1].type])[0]\n",
    "    list_personality.append(type_labelized)\n",
    "list_personality = np.array(list_personality)\n",
    "list_personality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "NS: Intuition (N) / Sensing (S)\n",
      "FT: Feeling (F) / Thinking (T)\n",
      "JP: Judging (J) / Perceiving (P)\n"
     ]
    }
   ],
   "source": [
    "personality_type = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) / Sensing (S)\", \n",
    "                   \"FT: Feeling (F) / Thinking (T)\", \"JP: Judging (J) / Perceiving (P)\"  ]\n",
    "\n",
    "for l in range(len(personality_type)):\n",
    "    print(personality_type[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "NS: Intuition (N) / Sensing (S)\n",
      "FT: Feeling (F) / Thinking (T)\n",
      "JP: Judging (J) / Perceiving (P)\n"
     ]
    }
   ],
   "source": [
    "personality_type = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) / Sensing (S)\", \n",
    "                   \"FT: Feeling (F) / Thinking (T)\", \"JP: Judging (J) / Perceiving (P)\"  ]\n",
    "\n",
    "for l in range(len(personality_type)):\n",
    "    print(personality_type[l])\n",
    "X_tfidf.shape\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X = svd.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "[0 0 0 ... 0 0 0]\n",
      "NS: Intuition (N) / Sensing (S)\n",
      "[0 0 0 ... 0 0 0]\n",
      "FT: Feeling (F) / Thinking (T)\n",
      "[1 1 0 ... 0 1 0]\n",
      "JP: Judging (J) / Perceiving (P)\n",
      "[1 0 1 ... 0 0 0]\n",
      "The final Accuracy is : 0.3234380393510528\n",
      "Weighted Precision: 66.05%\n",
      "Macro Precision: 61.68%\n",
      "Weighted Recall: 60.75%\n",
      "Macro Recall: 45.88%\n",
      "Weighted F1score: 60.71%\n",
      "Macro F1score: 48.71%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, list_personality, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "final_pred = np.zeros((X_test.shape[0], 4)) # 紀錄 4 個 model 分別預測病combine後的 MBTI 結果\n",
    "\n",
    "# XGBoost Model create\n",
    "for l in range(len(personality_type)):\n",
    "    \n",
    "    Y = y_train[:,l]\n",
    "\n",
    "\n",
    "    # fit model on training data\n",
    "    param = {}\n",
    "\n",
    "    param['n_estimators'] = 700 # after tunning\n",
    "    param['max_depth'] = 2\n",
    "    param['learning_rate'] = 0.12 # after tunning\n",
    "\n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(X_train, y_train[:,l])\n",
    "\n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 將四個預測結果合併成最後 MBTI 結果\n",
    "    for j in range(len(y_pred)):\n",
    "        final_pred[j][l] = y_pred[j]\n",
    "\n",
    "\n",
    "    # predictions = [round(value) for value in y_pred]\n",
    "    # # evaluate predictions\n",
    "    # accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(personality_type[l])\n",
    "    print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, final_pred)\n",
    "print(f'The final Accuracy is : {accuracy}')\n",
    "\n",
    "precision_we = precision_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Precision: %.2f%%\" % (precision_we * 100.0))\n",
    "precision_ma = precision_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Precision: %.2f%%\" % (precision_ma * 100.0))\n",
    "\n",
    "recall_we = recall_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Recall: %.2f%%\" % (recall_we * 100.0))\n",
    "recall_ma = recall_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Recall: %.2f%%\" % (recall_ma * 100.0))\n",
    "\n",
    "f1score_we = f1_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted F1score: %.2f%%\" % (f1score_we * 100.0))\n",
    "f1score_ma = f1_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro F1score: %.2f%%\" % (f1score_ma * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "[0 0 0 ... 0 0 0]\n",
      "NS: Intuition (N) / Sensing (S)\n",
      "[0 0 0 ... 0 0 0]\n",
      "FT: Feeling (F) / Thinking (T)\n",
      "[1 1 0 ... 0 1 0]\n",
      "JP: Judging (J) / Perceiving (P)\n",
      "[1 1 1 ... 1 0 0]\n",
      "The final Accuracy is : 0.329996548153262\n",
      "Weighted Precision: 70.20%\n",
      "Macro Precision: 69.62%\n",
      "Weighted Recall: 62.61%\n",
      "Macro Recall: 43.67%\n",
      "Weighted F1score: 58.98%\n",
      "Macro F1score: 43.15%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, list_personality, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "final_pred = np.zeros((X_test.shape[0], 4)) # 紀錄 4 個 model 分別預測病combine後的 MBTI 結果\n",
    "\n",
    "# XGBoost Model create\n",
    "for l in range(len(personality_type)):\n",
    "    \n",
    "    Y = y_train[:,l]\n",
    "\n",
    "\n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train[:,l])\n",
    "\n",
    "    # make predictions for test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # 將四個預測結果合併成最後 MBTI 結果\n",
    "    for j in range(len(y_pred)):\n",
    "        final_pred[j][l] = y_pred[j]\n",
    "\n",
    "\n",
    "    # predictions = [round(value) for value in y_pred]\n",
    "    # # evaluate predictions\n",
    "    # accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(personality_type[l])\n",
    "    print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, final_pred)\n",
    "print(f'The final Accuracy is : {accuracy}')\n",
    "\n",
    "precision_we = precision_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Precision: %.2f%%\" % (precision_we * 100.0))\n",
    "precision_ma = precision_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Precision: %.2f%%\" % (precision_ma * 100.0))\n",
    "\n",
    "recall_we = recall_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Recall: %.2f%%\" % (recall_we * 100.0))\n",
    "recall_ma = recall_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Recall: %.2f%%\" % (recall_ma * 100.0))\n",
    "\n",
    "f1score_we = f1_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted F1score: %.2f%%\" % (f1score_we * 100.0))\n",
    "f1score_ma = f1_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro F1score: %.2f%%\" % (f1score_ma * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "[0 0 0 ... 0 0 0]\n",
      "NS: Intuition (N) / Sensing (S)\n",
      "[0 0 0 ... 0 0 0]\n",
      "FT: Feeling (F) / Thinking (T)\n",
      "[1 1 0 ... 0 1 0]\n",
      "JP: Judging (J) / Perceiving (P)\n",
      "[1 1 1 ... 1 1 0]\n",
      "The final Accuracy is : 0.3224024853296514\n",
      "Weighted Precision: 57.10%\n",
      "Macro Precision: 47.18%\n",
      "Weighted Recall: 63.44%\n",
      "Macro Recall: 42.81%\n",
      "Weighted F1score: 57.03%\n",
      "Macro F1score: 39.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenenying/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/chenenying/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, list_personality, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "final_pred = np.zeros((X_test.shape[0], 4)) # 紀錄 4 個 model 分別預測病combine後的 MBTI 結果\n",
    "\n",
    "# XGBoost Model create\n",
    "for l in range(len(personality_type)):\n",
    "    \n",
    "    Y = y_train[:,l]\n",
    "\n",
    "\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train,y_train[:,l])\n",
    "\n",
    "    # make predictions for test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # 將四個預測結果合併成最後 MBTI 結果\n",
    "    for j in range(len(y_pred)):\n",
    "        final_pred[j][l] = y_pred[j]\n",
    "\n",
    "\n",
    "    # predictions = [round(value) for value in y_pred]\n",
    "    # # evaluate predictions\n",
    "    # accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(personality_type[l])\n",
    "    print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, final_pred)\n",
    "print(f'The final Accuracy is : {accuracy}')\n",
    "\n",
    "precision_we = precision_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Precision: %.2f%%\" % (precision_we * 100.0))\n",
    "precision_ma = precision_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Precision: %.2f%%\" % (precision_ma * 100.0))\n",
    "\n",
    "recall_we = recall_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Recall: %.2f%%\" % (recall_we * 100.0))\n",
    "recall_ma = recall_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Recall: %.2f%%\" % (recall_ma * 100.0))\n",
    "\n",
    "f1score_we = f1_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted F1score: %.2f%%\" % (f1score_we * 100.0))\n",
    "f1score_ma = f1_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro F1score: %.2f%%\" % (f1score_ma * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "[0 0 0 ... 0 0 0]\n",
      "NS: Intuition (N) / Sensing (S)\n",
      "[0 0 0 ... 1 0 1]\n",
      "FT: Feeling (F) / Thinking (T)\n",
      "[1 1 0 ... 0 1 0]\n",
      "JP: Judging (J) / Perceiving (P)\n",
      "[1 1 1 ... 0 0 0]\n",
      "The final Accuracy is : 0.27062478425957887\n",
      "Weighted Precision: 57.99%\n",
      "Macro Precision: 50.22%\n",
      "Weighted Recall: 65.10%\n",
      "Macro Recall: 51.35%\n",
      "Weighted F1score: 60.77%\n",
      "Macro F1score: 49.95%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, list_personality, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "final_pred = np.zeros((X_test.shape[0], 4)) # 紀錄 4 個 model 分別預測病combine後的 MBTI 結果\n",
    "\n",
    "# XGBoost Model create\n",
    "for l in range(len(personality_type)):\n",
    "    \n",
    "    Y = y_train[:,l]\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train,y_train[:,l]).predict(X_test)\n",
    "\n",
    "    # 將四個預測結果合併成最後 MBTI 結果\n",
    "    for j in range(len(y_pred)):\n",
    "        final_pred[j][l] = y_pred[j]\n",
    "\n",
    "\n",
    "    # predictions = [round(value) for value in y_pred]\n",
    "    # # evaluate predictions\n",
    "    # accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(personality_type[l])\n",
    "    print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, final_pred)\n",
    "print(f'The final Accuracy is : {accuracy}')\n",
    "\n",
    "precision_we = precision_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Precision: %.2f%%\" % (precision_we * 100.0))\n",
    "precision_ma = precision_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Precision: %.2f%%\" % (precision_ma * 100.0))\n",
    "\n",
    "recall_we = recall_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Recall: %.2f%%\" % (recall_we * 100.0))\n",
    "recall_ma = recall_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Recall: %.2f%%\" % (recall_ma * 100.0))\n",
    "\n",
    "f1score_we = f1_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted F1score: %.2f%%\" % (f1score_we * 100.0))\n",
    "f1score_ma = f1_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro F1score: %.2f%%\" % (f1score_ma * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "[0 0 0 ... 0 0 1]\n",
      "NS: Intuition (N) / Sensing (S)\n",
      "[0 0 0 ... 0 0 0]\n",
      "FT: Feeling (F) / Thinking (T)\n",
      "[1 1 1 ... 0 1 1]\n",
      "JP: Judging (J) / Perceiving (P)\n",
      "[1 1 1 ... 0 1 0]\n",
      "The final Accuracy is : 0.2599240593717639\n",
      "Weighted Precision: 58.03%\n",
      "Macro Precision: 52.68%\n",
      "Weighted Recall: 56.57%\n",
      "Macro Recall: 42.35%\n",
      "Weighted F1score: 55.35%\n",
      "Macro F1score: 43.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, list_personality, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "final_pred = np.zeros((X_test.shape[0], 4)) # 紀錄 4 個 model 分別預測病combine後的 MBTI 結果\n",
    "\n",
    "# XGBoost Model create\n",
    "for l in range(len(personality_type)):\n",
    "    \n",
    "    Y = y_train[:,l]\n",
    "    \n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train,y_train[:,l])\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # 將四個預測結果合併成最後 MBTI 結果\n",
    "    for j in range(len(y_pred)):\n",
    "        final_pred[j][l] = y_pred[j]\n",
    "\n",
    "\n",
    "    # predictions = [round(value) for value in y_pred]\n",
    "    # # evaluate predictions\n",
    "    # accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(personality_type[l])\n",
    "    print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, final_pred)\n",
    "print(f'The final Accuracy is : {accuracy}')\n",
    "\n",
    "precision_we = precision_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Precision: %.2f%%\" % (precision_we * 100.0))\n",
    "precision_ma = precision_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Precision: %.2f%%\" % (precision_ma * 100.0))\n",
    "\n",
    "recall_we = recall_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Recall: %.2f%%\" % (recall_we * 100.0))\n",
    "recall_ma = recall_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Recall: %.2f%%\" % (recall_ma * 100.0))\n",
    "\n",
    "f1score_we = f1_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted F1score: %.2f%%\" % (f1score_we * 100.0))\n",
    "f1score_ma = f1_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro F1score: %.2f%%\" % (f1score_ma * 100.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "[0 0 0 ... 0 1 1]\n",
      "NS: Intuition (N) / Sensing (S)\n",
      "[0 0 0 ... 0 0 0]\n",
      "FT: Feeling (F) / Thinking (T)\n",
      "[0 1 1 ... 0 1 1]\n",
      "JP: Judging (J) / Perceiving (P)\n",
      "[0 0 0 ... 0 0 0]\n",
      "The final Accuracy is : 0.17500862961684502\n",
      "Weighted Precision: 52.01%\n",
      "Macro Precision: 43.23%\n",
      "Weighted Recall: 50.98%\n",
      "Macro Recall: 42.73%\n",
      "Weighted F1score: 51.48%\n",
      "Macro F1score: 42.97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, list_personality, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "final_pred = np.zeros((X_test.shape[0], 4)) # 紀錄 4 個 model 分別預測病combine後的 MBTI 結果\n",
    "\n",
    "# XGBoost Model create\n",
    "for l in range(len(personality_type)):\n",
    "    \n",
    "    Y = y_train[:,l]\n",
    "    \n",
    "\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_train, y_train[:,l])\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # 將四個預測結果合併成最後 MBTI 結果\n",
    "    for j in range(len(y_pred)):\n",
    "        final_pred[j][l] = y_pred[j]\n",
    "\n",
    "\n",
    "    # predictions = [round(value) for value in y_pred]\n",
    "    # # evaluate predictions\n",
    "    # accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(personality_type[l])\n",
    "    print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, final_pred)\n",
    "print(f'The final Accuracy is : {accuracy}')\n",
    "\n",
    "precision_we = precision_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Precision: %.2f%%\" % (precision_we * 100.0))\n",
    "precision_ma = precision_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Precision: %.2f%%\" % (precision_ma * 100.0))\n",
    "\n",
    "recall_we = recall_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted Recall: %.2f%%\" % (recall_we * 100.0))\n",
    "recall_ma = recall_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro Recall: %.2f%%\" % (recall_ma * 100.0))\n",
    "\n",
    "f1score_we = f1_score(y_test, final_pred, average='weighted')\n",
    "print(\"Weighted F1score: %.2f%%\" % (f1score_we * 100.0))\n",
    "f1score_ma = f1_score(y_test, final_pred, average='macro')\n",
    "print(\"Macro F1score: %.2f%%\" % (f1score_ma * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4a4ba1db5610b5ef8ea6f761f191f567ff5b409f02c1cd41f72dbaaf0303b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
